{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea3afccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "import scipy as sp\n",
    "import scipy.stats as st\n",
    "import scipy.special as ss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "93041ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf():\n",
    "    \"\"\"Base Class for Leafs/ Roots of all types\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    tree : Tree\n",
    "        reference to the tree the leaf belongs to\n",
    "        \n",
    "    parent : Leaf/Root\n",
    "        reference to the node one hierarchy level above\n",
    "        \n",
    "    tested : bool\n",
    "        variable used during tree search that tells wether\n",
    "        everything beneath that tree has been already checked\n",
    "        True -> step to the other leaf of the parent node   \n",
    "        \n",
    "    x : np.array [N, D]\n",
    "        input data\n",
    "        \n",
    "    r : np.array [N, 1]\n",
    "        residuals\n",
    "        \n",
    "    p : np.array [N, 1]\n",
    "        probability of output (only relevant for Classification)\n",
    "        \n",
    "    depth : int\n",
    "        current level of inside the tree hierarchy\n",
    "        \n",
    "    Methods\n",
    "    -------\n",
    "    to_root() -> void\n",
    "        Change Class of object from Leaf-child to Root-child\n",
    "        \n",
    "    can_be_split() -> bool\n",
    "        Decide whether obj of class Leaf-child should be changed to Root-child\n",
    "        \n",
    "    leaf_metric() -> np.array []\n",
    "    leaf_output() -> np.array []\n",
    "    \"\"\"\n",
    "    def __init__(self, tree, parent, x, r, p, depth = 1):\n",
    "        self.tree = tree\n",
    "        self.parent = parent\n",
    "        self.tested = False\n",
    "        \n",
    "        self.x = x\n",
    "        self.r = r\n",
    "        self.p = p\n",
    "        \n",
    "        self.depth = depth\n",
    "        \n",
    "    def to_root(self):\n",
    "        \"\"\"Change Class of object from Leaf-child to Root-child\n",
    "        \"\"\"\n",
    "        if type(self) == self.tree.leaf_cls:\n",
    "            self.__class__ = self.tree.root_cls\n",
    "            self.__init__(self.tree, self.parent, self.x, self.r, self.p, self.depth)\n",
    "        \n",
    "    def can_be_split(self):\n",
    "        \"\"\"Decide whether obj of class Leaf-child should be changed to Root-child\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        cond_1 : bool\n",
    "            make sure the leaf contains at least 2 samples, so that splitting even makes sense\n",
    "            \n",
    "        cond_2 : bool\n",
    "            the tree has not yet grown to its final depth\n",
    "        \n",
    "        cond_3 : bool\n",
    "            self is instance of a Leaf-child, not of Root-child\n",
    "            That is important because during the init of Root this method will be used as well, \n",
    "            since Root is a child of Leaf.\n",
    "            However we only want to test if a Leaf can be split, \n",
    "            otherwise there will be an infinite init loop. \n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        can_be_sṕlit : bool\n",
    "        \n",
    "        \"\"\"\n",
    "        cond_1 = (self.x.shape[0] >= 2)\n",
    "        cond_2 = (self.depth <= self.tree.max_depth)\n",
    "        \n",
    "        can_be_sṕlit = cond_1 and cond_2\n",
    "        return can_be_sṕlit \n",
    "    \n",
    "    def leaf_metric(self):\n",
    "        \"\"\"Error or Simliarity metric of a leaf.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def leaf_output(self):\n",
    "        \"\"\"Formula that gives a single output for all residuals in a leaf.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "class XGBLeaf(Leaf):\n",
    "    \"\"\"Leaf with the specific XGBoost split criteria and output\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    lampda : np.array []\n",
    "        regularization constant\n",
    "        \n",
    "    gamma : np.array []\n",
    "        minimum gain value as pruning condition\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    leaf_metric() -> np.array [] \n",
    "    leaf_output() -> np.array []\n",
    "    cover()       -> np.array []\n",
    "    \"\"\"\n",
    "    def __init__(self, tree, parent, x, r, p, depth = 1):\n",
    "        super(XGBLeaf, self).__init__(tree, parent, x, r, p, depth)\n",
    "        self.lampda = self.tree.lampda\n",
    "        self.gamma = self.tree.gamma\n",
    "        \n",
    "    def leaf_metric(self):\n",
    "        \"\"\"Similiarity of residuals inside the leaf\n",
    "        Arguments\n",
    "        ---------\n",
    "        r : np.array [N,1]\n",
    "        p : np.array [N,1]\n",
    "        lampda : np.array []\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        similiarity : np.array []\n",
    "        \"\"\"\n",
    "        similiarity = (self.r.sum()[np.newaxis] ** 2) / (self.cover() + self.lampda)\n",
    "        return similiarity\n",
    "\n",
    "    def leaf_output(self):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        r : np.array [N,1]\n",
    "        p : np.array [N,1]\n",
    "        lampda : np.array []\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        gamma_mj : np.array []\n",
    "        \"\"\"\n",
    "        gamma_mj = self.r.sum()[np.newaxis] / (self.cover() + self.lampda)\n",
    "        return gamma_mj\n",
    "    \n",
    "    def cover(self):\n",
    "        \"\"\"Hessian of the Loss function\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    \n",
    "    \n",
    "class XGBLeafRegression(XGBLeaf):\n",
    "    def __init__(self, tree, parent, x, r, p, depth = 1):\n",
    "        super(XGBLeafRegression, self).__init__(tree, parent, x, r, p, depth)\n",
    "    \n",
    "    def cover(self):\n",
    "        \"\"\"Hessian of the loss: number of residuals in leaf\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        r : np.array [N,1]\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        cover : np.array []\n",
    "\n",
    "        \"\"\"\n",
    "        return len(self.r)\n",
    "\n",
    "    \n",
    "class XGBLeafClassification(XGBLeaf):\n",
    "    def __init__(self, tree, parent, x, r, p, depth = 1):\n",
    "        super(XGBLeafClassification, self).__init__(tree, parent, x, r, p, depth)\n",
    "    \n",
    "    def cover(self):\n",
    "        \"\"\"Hessian of the loss: Gini Index \n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        p : np.array [N,1]\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        cover : np.array []\n",
    "\n",
    "        \"\"\"\n",
    "        q = np.ones_like(self.p) - self.p\n",
    "        cover = (self.p * q).sum()\n",
    "        return cover\n",
    "\n",
    "     \n",
    "def root_inherit_from(base):\n",
    "    class Root(base):\n",
    "        \"\"\"Base Class for Decision Tree\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        d_split : np.array []\n",
    "            dimension along which the split is performed\n",
    "            tells which input feature should be compared to boundary\n",
    "\n",
    "        x_d_split : np.array []\n",
    "            x value of highest split gain along d_split\n",
    "            tells the boundary to compare to during output assignment\n",
    "\n",
    "        metric_opt : np.array []\n",
    "            highest split gain\n",
    "            tells wether split should be kept during pruning\n",
    "            \n",
    "        leaf_1 : Leaf/Root\n",
    "        leaf_2 : Leaf/Root\n",
    "        \n",
    "        Methods\n",
    "        -------\n",
    "        find_best_spĺit()\n",
    "            Get parameters for the optimal split into 2 leafs\n",
    "            \n",
    "        root_metric()\n",
    "            Metric that decides how useful the split is\n",
    "            \n",
    "        get_boundaries()\n",
    "            Return all boundaries that should be tested for a given dim\n",
    "            \n",
    "        split_root()\n",
    "            Given the optimal split parameters, create 2 new leafs\n",
    "            \n",
    "        grow_tree_further()\n",
    "            If possible, turn leafs of the root into new roots\n",
    "        \"\"\"\n",
    "        def __init__(self, tree, parent, x, r, p, depth = 1):\n",
    "            super(Root, self).__init__(tree, parent, x, r, p, depth)\n",
    "            (self.d_split,\n",
    "             self.x_d_split,\n",
    "             self.metric_opt) = self.find_best_split(x, r, p)\n",
    "\n",
    "            (self.leaf_1,\n",
    "             self.leaf_2) = self.split_root(x, r, p, self.d_split, self.x_d_split) \n",
    "\n",
    "            self.grow_tree_further()\n",
    "\n",
    "\n",
    "\n",
    "        ##############################################################################\n",
    "        # TREE CREATION ##############################################################\n",
    "        ##############################################################################\n",
    "\n",
    "        def find_best_split(self, x, r, p):\n",
    "            \"\"\"Get parameters for the optimal split into 2 leafs\n",
    "            \n",
    "            Arguments\n",
    "            ---------\n",
    "            x : np.array [N, d]\n",
    "            r : np.array [N, 1]\n",
    "            p : np.array [N, 1]\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            d_split : np.array []\n",
    "            x_d_split : np.array []\n",
    "            metric_opt : np.array []\n",
    "            \"\"\"\n",
    "            metric_opt = -np.inf\n",
    "\n",
    "            # for every feature of the input data\n",
    "            for d in range(x.shape[-1]):\n",
    "\n",
    "                # sort samples so that the d'th feature increases in a monotonous way\n",
    "                idx = x[:,d].argsort()\n",
    "                x_d = x[idx, d]\n",
    "                r = r[idx]\n",
    "                p = p[idx]\n",
    "\n",
    "                # for every possible boundary \n",
    "                splits = self.get_boundaries(x_d)\n",
    "                for split in splits:\n",
    "\n",
    "                    # create two new leafs\n",
    "                    leaf_1, leaf_2 = self.split_root(x, r, p, d, split)\n",
    "\n",
    "                    # check if metric val beats so far best metric val\n",
    "                    metric = self.root_metric(leaf_1, leaf_2)\n",
    "\n",
    "                    if metric > metric_opt:\n",
    "                        metric_opt = metric\n",
    "                        d_split = d\n",
    "                        x_d_split = split\n",
    "\n",
    "            return d_split, x_d_split, metric_opt\n",
    "\n",
    "\n",
    "        def root_metric(self, leaf_1, leaf_2):\n",
    "            \"\"\"Similiarity gain\n",
    "\n",
    "            Arguments\n",
    "            ---------\n",
    "            leaf_1\n",
    "            leaf_2\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            gain : np.array []\n",
    "            \"\"\"        \n",
    "            gain = leaf_1.leaf_metric() \\\n",
    "                 + leaf_2.leaf_metric() \\\n",
    "                 - self.leaf_metric()\n",
    "            return gain\n",
    "\n",
    "\n",
    "        def get_boundaries(self, x_d):\n",
    "            \"\"\"Return all boundaries that should be tested for a given dim\n",
    "\n",
    "            Arguments\n",
    "            ---------\n",
    "            x_d : np.array [N]\n",
    "\n",
    "            Returns\n",
    "            ------\n",
    "            boundaries : list of np.array [0]\n",
    "            \"\"\"\n",
    "            boundaries = [(x_d[i] + x_d[i+1])/2 for i in range(x_d.shape[0]-1)]\n",
    "            return boundaries\n",
    "\n",
    "\n",
    "        def split_root(self, x, r, p, d_split, x_d_split):\n",
    "            \"\"\"Given the optimal split parameters, create 2 new leafs\n",
    "\n",
    "            Arguments\n",
    "            ---------\n",
    "            x : np.array [N, d]\n",
    "            r : np.array [N, 1]\n",
    "            d_split: int\n",
    "            x_d_split : np.array []\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            leaf_1 : object of type Leaf-child\n",
    "            leaf_2 : object of type Leaf-child\n",
    "            \"\"\"\n",
    "            mask = x[:,d_split] < x_d_split\n",
    "            leaf_1 = self.tree.leaf_cls(self.tree, self, x[mask], r[mask], p[mask], self.depth + 1)\n",
    "            leaf_2 = self.tree.leaf_cls(self.tree, self, x[~mask], r[~mask], p[~mask], self.depth + 1)\n",
    "            return leaf_1, leaf_2\n",
    "\n",
    "\n",
    "        def grow_tree_further(self):\n",
    "            \"\"\"If possible, turn leafs of the root into new roots\n",
    "            \"\"\"\n",
    "            if self.leaf_1.can_be_split():\n",
    "                self.leaf_1.to_root()\n",
    "\n",
    "            if self.leaf_2.can_be_split():\n",
    "                self.leaf_2.to_root()\n",
    "\n",
    "\n",
    "        ##########################################################################\n",
    "        # PRUNING ################################################################\n",
    "        ##########################################################################\n",
    "\n",
    "        def prune_bool(self):\n",
    "            \"\"\"Tells wether root should be pruned\n",
    "\n",
    "            Arguments\n",
    "            ---------\n",
    "            cond_1 : bool\n",
    "                the error improvement from splitting is sufficient\n",
    "\n",
    "            cond_2 : bool\n",
    "                make sure to not delete entire tree\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            prune : bool\n",
    "\n",
    "            \"\"\"\n",
    "            cond_1 = self.metric_opt < self.tree.gamma\n",
    "            cond_2 = self.parent != self.tree\n",
    "            prune = cond_1 and cond_2\n",
    "            return prune\n",
    "\n",
    "        def to_leaf(self):\n",
    "            \"\"\"Change Class of object from Root-child to Leaf-child\n",
    "            \"\"\"\n",
    "            if type(self) == self.tree.root_cls:\n",
    "                self.__class__ = self.tree.leaf_cls\n",
    "                self.__init__(self.tree, self.parent, self.x, self.r, self.p, self.depth)\n",
    "                \n",
    "    return Root\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "class Tree():\n",
    "    \"\"\"\n",
    "    Attributes\n",
    "    ----------\n",
    "    max_depth\n",
    "        number of splits, counted along the vertical axis\n",
    "        \n",
    "    root_cls\n",
    "        Class of root objects that will build the tree\n",
    "        \n",
    "    lef_cls\n",
    "        Class of the Leaf objects that will build the tree\n",
    "        \n",
    "    root\n",
    "        First split of the tree. \n",
    "        All roots and leafs of the tree are recursively contained inside this root.\n",
    "        \n",
    "    lampda : np.array []\n",
    "        regularization constant\n",
    "        \n",
    "    gamma : np.array []\n",
    "        minimum gain value as pruning condition\n",
    "        \n",
    "    Methods\n",
    "    -------\n",
    "    fit_tree()\n",
    "        Fit Tree to the data\n",
    "        \n",
    "    prune_tree()\n",
    "        From bottom up unite all not useful splits into a leaf\n",
    "        \n",
    "    single_sample_output()\n",
    "        Go down the whole tree based on a single x_i sample\n",
    "        \n",
    "    output()\n",
    "        For data x create predictions gamma\n",
    "        \n",
    "    search_tree()\n",
    "        Walk trough all roots of the tree\n",
    "        \n",
    "    root_is_final_root()\n",
    "        Set the attribute \"tested\" of all roots in the tree to False\n",
    "        Must be done after searching / pruning\n",
    "        \n",
    "    step_from_intermediate_root()\n",
    "        Get next root during tree search, \n",
    "        if root has root/root, root/leaf, leaf/root\n",
    "        \n",
    "    step_from_final_root()\n",
    "        Get next root during tree search, if root has leaf leaf. \n",
    "        Prune if necessary.\n",
    "        \n",
    "    step_root()\n",
    "        Recursively Step trough all roots of the tree, used for pruning\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self, LeafClass, RootClass, max_depth, lampda, gamma):\n",
    "        self.max_depth = max_depth\n",
    "        self.root_cls = RootClass\n",
    "        self.leaf_cls = LeafClass\n",
    "        \n",
    "        self.root = None\n",
    "        self.lampda = lampda\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def fit_tree(self, x, r, p):\n",
    "        \"\"\"Fit Tree to the data\n",
    "        \"\"\"\n",
    "        self.root = self.root_cls(tree=self, \n",
    "                                  parent=self,\n",
    "                                  x=x,\n",
    "                                  r=r,\n",
    "                                  p=p)\n",
    "        \n",
    "    def prune_tree(self):\n",
    "        \"\"\"From bottom up unite all not useful splits into a leaf\n",
    "        \"\"\"\n",
    "        self.step_root(self.root, prune_during_search = False)\n",
    "        self.reset_search_attribute(self.root)\n",
    "       \n",
    "\n",
    "    def single_sample_output(self, root, x_i):\n",
    "        \"\"\"Go down the whole tree based on a single x_i sample\n",
    "        Arguments\n",
    "        ---------\n",
    "        x_i : np.array [N]\n",
    "        root\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        root\n",
    "        \"\"\"\n",
    "        if type(root) == self.root_cls:\n",
    "            if x_i[root.d_split] < root.x_d_split:\n",
    "                return self.single_sample_output(root.leaf_1, x_i)\n",
    "            else:\n",
    "                return self.single_sample_output(root.leaf_2, x_i)\n",
    "                \n",
    "        if type(root) == self.leaf_cls:\n",
    "            return root.leaf_output()\n",
    "        \n",
    "    def output(self, x):\n",
    "        \"\"\"For data x create predictions gamma\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        x : np.array [N, d]\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        gamma : np.array [N, 1]\n",
    "        \"\"\"\n",
    "            \n",
    "        r = np.stack([self.single_sample_output(self.root, x_i) for x_i in x])\n",
    "        return r\n",
    "\n",
    "        \n",
    "    def search_tree(self):\n",
    "        \"\"\"Walk trough all roots of the tree\n",
    "        \"\"\"\n",
    "        self.step_root(self.root, prune_during_search = False)\n",
    "        self.reset_search_attribute(self.root)\n",
    "        \n",
    "    def reset_search_attribute(self, root):\n",
    "        \"\"\"Set the attribute \"tested\" of all roots in the tree to False. Must be done after searching / pruning.\n",
    "        \"\"\"\n",
    "        if type(root) == self.root_cls:\n",
    "            root.tested = False\n",
    "            return self.reset_search_attribute(root.leaf_1), self.reset_search_attribute(root.leaf_2)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def step_from_intermediate_root(self, root):\n",
    "        \"\"\"Get next root during tree search, if root has root/root, root/leaf, leaf/root\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        root\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        root\n",
    "        \"\"\"\n",
    "        if not root.leaf_1.tested and not root.leaf_2.tested:\n",
    "            return root.leaf_1\n",
    "        if root.leaf_1.tested and not root.leaf_2.tested:\n",
    "            return root.leaf_2\n",
    "        if root.leaf_1.tested and root.leaf_2.tested:\n",
    "            root.tested = True\n",
    "            return root.parent\n",
    "        \n",
    "    def step_from_final_root(self, root, prune_during_search):\n",
    "        \"\"\"Get next root during tree search, if root has leaf leaf. Prune if necessary.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        root\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        root\n",
    "        \"\"\"\n",
    "        if root.prune_bool() and prune_during_search:\n",
    "            root.to_leaf()\n",
    "        root.tested = True\n",
    "        return root.parent\n",
    "    \n",
    "    def root_is_final_root(self, root):\n",
    "        \"\"\"Determine wether root has two leafs\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        root : self.root_cls object\n",
    "        \n",
    "        Return\n",
    "        ------\n",
    "        root_has_leaf_leaf : bool\n",
    "        \"\"\"\n",
    "        root_has_leaf_leaf = type(root.leaf_1) == self.leaf_cls and type(root.leaf_2) == self.leaf_cls\n",
    "        return root_has_leaf_leaf\n",
    "        \n",
    "        \n",
    "    def step_root(self, root, prune_during_search = False):\n",
    "        \"\"\"Recursively Step trough all roots of the tree, used for pruning\n",
    "        \"\"\"\n",
    "        if type(root) == self.root_cls:\n",
    "            if not self.root_is_final_root(root) :\n",
    "                root = self.step_from_intermediate_root(root)\n",
    "            else:\n",
    "                root =  self.step_from_final_root(root, prune_during_search)\n",
    "            return self.step_root(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fff19607",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoost():\n",
    "    \"\"\"\n",
    "    Attributes\n",
    "    ----------\n",
    "    num_trees : int\n",
    "        corresponds to M. There are m = 1,...,M trees. \n",
    "        However there are M+1 models, since for m=0 there is a constant F_0.\n",
    "        \n",
    "    learning_rate : np.array []\n",
    "        Stepsize of the Gradient Descent\n",
    "    \n",
    "    F_0 : np.array [N, 1]\n",
    "        Initial Prediction, usually the mean of the labels.\n",
    "    \n",
    "    root_cls\n",
    "        Class of root objects that will build the trees of XGBoost\n",
    "        \n",
    "    tree : list of Tree\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    loss()\n",
    "    residuals()\n",
    "    initial_prediction()\n",
    "    output()\n",
    "    fit()\n",
    "    \"\"\"\n",
    "    def __init__(self, num_trees, max_depth, learning_rate, lampda, gamma):\n",
    "        self.num_trees = num_trees\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.F_0 = 0.\n",
    "        \n",
    "        self.root_cls = root_inherit_from(self.leaf_cls)\n",
    "        self.trees = [Tree(self.leaf_cls, \n",
    "                           self.root_cls, \n",
    "                           max_depth,\n",
    "                           lampda,\n",
    "                           gamma) \n",
    "                      for m in range(num_trees)] \n",
    "        \n",
    "    def loss_fn(self):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        F_m : np.array [N, 1]  \n",
    "        p_m : np.array [N, 1]\n",
    "        y : np.array [N, 1]\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        L_m : np.array []\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    \n",
    "    def residual_fn(self):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        F_m : np.array [N, 1]            \n",
    "        y : np.array [N, 1]\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        r_m : np.array [N, 1]\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    \n",
    "    def initial_prediction(self):\n",
    "        \"\"\"Prediction of first model (not a tree)\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        y : np.array [N, 1]\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        F_m : np.array [N, 1]\n",
    "        p_m : np.array [N, 1]\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        \n",
    "    def output_layer(self):\n",
    "        \"\"\"Apply final layer to convert Model output to labels\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        F_m : np.array [N, 1]\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        y_pred : np.array [N, 1]\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        \"\"\"Fit Model to the data\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        x : np.array [N, d]\n",
    "            input data\n",
    "            \n",
    "        y : np.array [N, 1]\n",
    "            labels\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        loss = list()\n",
    "        F_m, p_m = self.initial_prediction(y)\n",
    "        for m in range(self.num_trees):\n",
    "            # Loss\n",
    "            L_m = self.loss_fn(y, F_m, p_m)\n",
    "            loss.append(L_m)\n",
    "            \n",
    "            # Fit tree\n",
    "            r_m = self.residual_fn(y, F_m)\n",
    "            self.trees[m].fit_tree(x, r_m, p_m)\n",
    "            \n",
    "            # Update Model output\n",
    "            gamma_m = self.trees[m].output(x)\n",
    "            F_m = F_m + self.learning_rate * gamma_m\n",
    "            p_m = ss.expit(F_m)\n",
    "        \n",
    "        self.loss = loss\n",
    "        \n",
    "        \n",
    "    def predict(self, x):\n",
    "        \"\"\"Predict new labels for unseen input data\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        x : np.array [N, d]\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        y_pred : np.array [N, 1]\n",
    "        \"\"\"\n",
    "        F_m = self.F_0\n",
    "        for m in range(self.num_trees):\n",
    "            gamma_m = self.trees[m].output(x)\n",
    "            F_m = F_m + self.learning_rate * gamma_m\n",
    "        y_pred = self.output_layer(F_m)\n",
    "        return y_pred\n",
    "    \n",
    "    \n",
    "class XGBoostRegression(XGBoost):\n",
    "    def __init__(self, num_trees, max_depth, learning_rate, lampda, gamma):\n",
    "        self.leaf_cls = XGBLeafRegression\n",
    "        super(XGBoostRegression, self).__init__(num_trees, max_depth, learning_rate, lampda, gamma) \n",
    "            \n",
    "            \n",
    "    def loss_fn(self, y, F_m, p_m):\n",
    "        L_m = ((y - F_m) ** 2).mean()\n",
    "        return L_m\n",
    "    \n",
    "    \n",
    "    def residual_fn(self, y, F_m):\n",
    "        r_m = y - F_m   \n",
    "        return r_m\n",
    "    \n",
    "    \n",
    "    def initial_prediction(self, y):\n",
    "        F_m = y.mean() * np.ones_like(y)\n",
    "        p_m = F_m\n",
    "        self.F_0 = F_m\n",
    "        return F_m, p_m\n",
    "    \n",
    "    \n",
    "    def output_layer(self, F_m):\n",
    "        return F_m\n",
    "    \n",
    "class XGBoostClassification(XGBoost):\n",
    "    def __init__(self, num_trees, max_depth, learning_rate, lampda, gamma):\n",
    "        self.leaf_cls = XGBLeafClassification\n",
    "        super(XGBoostClassification, self).__init__(num_trees, max_depth, learning_rate, lampda, gamma) \n",
    "    \n",
    "    \n",
    "    def loss_fn(self, y, F_m, p_m):\n",
    "        q_m = np.ones_like(p_m) - p_m\n",
    "        L_m = - (p_m * np.log(p_m) + q_m * np.log(q_m)).sum()\n",
    "        return L_m\n",
    "    \n",
    "    \n",
    "    def residual_fn(self, y, F_m):\n",
    "        r_m = y - ss.expit(F_m)  \n",
    "        return r_m\n",
    "    \n",
    "    \n",
    "    def initial_prediction(self, y):\n",
    "        p_m = y.mean() * np.ones_like(y)\n",
    "        F_m = ss.logit(p_m)\n",
    "        self.F_0 = F_m\n",
    "        return F_m, p_m\n",
    "\n",
    "    \n",
    "    def output_layer(self, F_m):\n",
    "        return ss.expit(F_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "68e1b38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 1)\n",
      "(40, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data\n",
    "K = 4\n",
    "N = K * 10\n",
    "D = 1\n",
    "x = np.arange(N)[:,np.newaxis].repeat(D,-1)\n",
    "y = np.concatenate([np.ones(int(N/K)) * i for i in range(K)], axis = 0)[:,np.newaxis]\n",
    "r = y - y.mean()\n",
    "plt.plot(x,y);\n",
    "plt.grid()\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fed68c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.25,\n",
       " 1.0125000000000002,\n",
       " 0.8201250000000002,\n",
       " 0.6643012500000001,\n",
       " 0.5380840125,\n",
       " 0.435848050125,\n",
       " 0.3530369206012501,\n",
       " 0.2859599056870127,\n",
       " 0.2316275236064802,\n",
       " 0.18761829412124903]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model\n",
    "model = XGBoostRegression(num_trees=10, max_depth=4, learning_rate=0.1, lampda=0, gamma=0)\n",
    "model.fit(x,y)\n",
    "plt.plot(model.predict(x))\n",
    "plt.grid()\n",
    "model.loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch] *",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
